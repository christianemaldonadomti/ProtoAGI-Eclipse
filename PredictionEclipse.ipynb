{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import requests\n",
        "\n",
        "# Fetch the JSON data from the URL\n",
        "url = 'https://svs.gsfc.nasa.gov/vis/a000000/a005000/a005073/cities-eclipse-2024.json'\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.json_normalize(data)\n",
        "\n",
        "# Data preprocessing\n",
        "df['ECLIPSE_START'] = pd.to_datetime(df['ECLIPSE'].apply(lambda x: x[0]), format='%H:%M:%S')\n",
        "df['ECLIPSE_START'] = df['ECLIPSE_START'].dt.hour * 60 + df['ECLIPSE_START'].dt.minute\n",
        "X = df[['LAT', 'LON']]\n",
        "y = df['ECLIPSE_START']\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define a DNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Checking for GPU and using it\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "    print(\"Using GPU for training\")\n",
        "else:\n",
        "    print(\"Using CPU for training\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "CDDe_j40JUAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUciCryiWqE4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Assuming you have a trained model and test set ready\n",
        "# X_test is your testing feature set, and y_test is the actual target values for the testing set\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Now you can calculate the performance metrics\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'R-squared (RÂ²): {r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# Assuming the model is already trained and available in the session\n",
        "# If you need to load it, you can use: model = keras.models.load_model('path_to_your_saved_model')\n",
        "\n",
        "def predict_eclipse_time(model, lat, lon, scaler):\n",
        "    # Convert user input into the format the model expects, here assuming it needs a 2D array\n",
        "    input_features = np.array([[lat, lon]])\n",
        "\n",
        "    # Assuming the scaler used in the training phase is also available\n",
        "    # If you need to load it, ensure you have it saved and accessible\n",
        "    input_features_scaled = scaler.transform(input_features)\n",
        "\n",
        "    # Making prediction\n",
        "    predicted_time = model.predict(input_features_scaled)\n",
        "\n",
        "    # Convert the predicted time from model output (if necessary, e.g., to HH:MM format)\n",
        "    return predicted_time\n",
        "\n",
        "# Main function to handle user interaction\n",
        "def main(model, scaler):\n",
        "    print(\"Please enter your coordinates to predict the eclipse time.\")\n",
        "\n",
        "    # User inputs latitude and longitude\n",
        "    lat = float(input(\"Enter latitude (e.g., 34.0522): \"))\n",
        "    lon = float(input(\"Enter longitude (e.g., -118.2437): \"))\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = predict_eclipse_time(model, lat, lon, scaler)\n",
        "    print(f\"Predicted eclipse start time (in model's output format, e.g., minutes past midnight): {prediction[0]}\")\n",
        "\n",
        "    # Constants\n",
        "    minutes_from_start = prediction[0]\n",
        "\n",
        "    # Calculate hours and minutes\n",
        "    total_hours = minutes_from_start / 60\n",
        "    hours = int(total_hours) - 6\n",
        "    minutes = (total_hours - hours) * 60\n",
        "\n",
        "    print(hours-6, minutes)\n",
        "\n",
        "# Assuming 'model' and 'scaler' are defined in your session\n",
        "main(model, scaler)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ejA5yIl5WZ0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qxyj9rx7SIMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c1xGFBsRQxb5"
      }
    }
  ]
}